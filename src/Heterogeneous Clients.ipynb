{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "de815565-e7de-4328-8edc-59845da230fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import client\n",
    "import server\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8448f73c-c53c-4461-b6e8-bf1d07c00b6c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils' from '/Users/gael/Desktop/het-opl/src/utils.py'>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(client)\n",
    "importlib.reload(server)\n",
    "importlib.reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "abcad7be-146d-4523-ae2d-265dfbdbeaba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from vowpalwabbit.sklearn import VW\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "21e33242-c491-48db-816f-6e923a2fb5ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a04c64fa-133b-4d07-9af1-f73aaeb9dc76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def givens_rotation(vec, i, j, theta):\n",
    "    \"\"\"\n",
    "    Apply a Givens rotation to a 1D NumPy array in the plane spanned by two given axes.\n",
    "\n",
    "    Args:\n",
    "    vec (np.array): The input 1D NumPy array.\n",
    "    i (int): The first axis.\n",
    "    j (int): The second axis.\n",
    "    theta (float): The rotation angle in radians.\n",
    "\n",
    "    Returns:\n",
    "    np.array: The resulting 1D NumPy array after applying the Givens rotation.\n",
    "    \"\"\"\n",
    "    if i >= len(vec) or j >= len(vec):\n",
    "        raise ValueError(\"Axes indices must be within the range of the input array.\")\n",
    "\n",
    "    if i == j:\n",
    "        raise ValueError(\"Axes indices must be different.\")\n",
    "\n",
    "    rotated_vec = vec.copy()\n",
    "    cos_theta = np.cos(theta)\n",
    "    sin_theta = np.sin(theta)\n",
    "\n",
    "    rotated_vec[i] = cos_theta * vec[i] - sin_theta * vec[j]\n",
    "    rotated_vec[j] = sin_theta * vec[i] + cos_theta * vec[j]\n",
    "\n",
    "    return rotated_vec\n",
    "\n",
    "def generate_separated_vectors_grid(n, s, k, num_vectors=4):\n",
    "    # Calculate the number of cells along each axis\n",
    "    num_cells = int(np.ceil(2 * s / k))\n",
    "\n",
    "    # Create a list of all cell indices\n",
    "    cell_indices = np.arange(num_cells ** n)\n",
    "    np.random.shuffle(cell_indices)\n",
    "\n",
    "    # Randomly select distinct cells for each of the num_vectors points\n",
    "    selected_cells = cell_indices[:num_vectors]\n",
    "\n",
    "    # Convert cell indices to n-dimensional grid indices\n",
    "    grid_indices = np.array(np.unravel_index(selected_cells, [num_cells] * n)).T\n",
    "\n",
    "    # Calculate the lower bound of each cell\n",
    "    lower_bounds = -s + grid_indices * k\n",
    "\n",
    "    # Sample a point within each of the chosen cells\n",
    "    vectors = lower_bounds + np.random.rand(num_vectors, n) * k\n",
    "\n",
    "    return vectors\n",
    "\n",
    "def generate_observational_data(num_clients, num_actions, num_features, train_sizes, test_sizes=None):\n",
    "    if test_sizes is None:\n",
    "        test_sizes = [10_000] * num_clients\n",
    "\n",
    "#     action_vec = np.random.randn(num_features)\n",
    "#     action_vec /= np.linalg.norm(action_vec)\n",
    "#     # action_vec *= 0.5\n",
    "    \n",
    "#     thetas = [k*np.pi/num_actions for k in range(num_actions)]\n",
    "#     action_params = np.array([givens_rotation(action_vec, 0, 1, theta) for theta in thetas])\n",
    "#     assert action_params.shape == (num_actions, num_features)\n",
    "\n",
    "#     # action_params = np.random.randn(num_features, num_actions)\n",
    "    # action_params /= np.linalg.norm(action_params, axis=0)\n",
    "    # action_params = 0.5 * action_params\n",
    "\n",
    "    action_params = generate_separated_vectors_grid(num_features, 1, np.sqrt(num_features), 4)\n",
    "\n",
    "    weights = []\n",
    "    for i in range(num_actions):\n",
    "        other_vectors = np.delete(action_params, [i], axis=0)\n",
    "        weights.append(sum([1/np.linalg.norm(action_params[i] - v) for v in other_vectors]))\n",
    "        if not all(np.linalg.norm(action_params[i] - v) > np.sqrt(num_features) for v in other_vectors):\n",
    "            raise ValueError(\"Vectors not sufficiently separated. Resample.\")\n",
    "    weights = [w / sum(weights) for w in weights]\n",
    "\n",
    "    data = {}\n",
    "    aux = {}\n",
    "    for client_id in range(num_clients):\n",
    "        # Generate data\n",
    "        num_samples = train_sizes[client_id] + test_sizes[client_id]\n",
    "        # contexts = np.random.uniform(low=-1, high=1, size=(num_samples, num_features))\n",
    "        # contexts = np.random.normal(loc=0, scale=1, size=(num_samples, num_features))\n",
    "        contexts = np.random.multivariate_normal(mean=action_params[client_id], cov=np.eye(num_features), size=num_samples)\n",
    "        rewards_vectors = np.zeros((num_samples, num_actions))\n",
    "        for i in range(num_samples):\n",
    "            for a in range(num_actions):\n",
    "                rewards_vectors[i, a] += np.dot(contexts[i], action_params[a])\n",
    "                if contexts[i][0] > 0.25:\n",
    "                    rewards_vectors[i, a] += -np.max([np.dot(contexts[i], action_params[aprime]) for aprime in range(num_actions)]) \n",
    "                # rewards_vectors[i, a] = np.clip(1 / np.linalg.norm(contexts[i] - action_params[a]), a_min=0, a_max=10)\n",
    "                # rewards_vectors[i, a] = np.exp(1-1/np.linalg.norm(contexts[i]-action_params[a]))\n",
    "                # rewards_vectors[i, a] = 1 - np.exp(-1/np.linalg.norm(contexts[i]-action_params[a]))\n",
    "        # actions = np.random.choice(num_actions, p=[0.7, 0.1, 0.1, 0.1], size=num_samples)\n",
    "        actions = np.random.choice(num_actions, size=num_samples)\n",
    "        epsilons = np.random.normal(loc=0, scale=1, size=(num_samples, num_actions))\n",
    "        noisy_rewards_vectors = rewards_vectors + epsilons\n",
    "        noisy_rewards = noisy_rewards_vectors[np.arange(num_samples), actions]\n",
    "        \n",
    "        # Get train-test split\n",
    "        (X_train, X_test,\n",
    "         A_train, A_test,\n",
    "         Y_train, Y_test,\n",
    "         true_costs_train, true_costs_test) = train_test_split(contexts, actions, noisy_rewards, -rewards_vectors,\n",
    "                                                               train_size=train_sizes[client_id],\n",
    "                                                               shuffle=False)\n",
    "\n",
    "        # Compute AIPW scores\n",
    "        crossfit_map, mu, e = utils.cross_fit_nuisance_params(X_train, A_train, Y_train, num_actions)\n",
    "        AIPW_vectors = utils.compute_AIPW_scores(X_train, A_train, Y_train, num_actions, crossfit_map, mu, e)\n",
    "\n",
    "        # Convert data to VW format\n",
    "        vw_data = utils.to_vw_format(X_train, A_train, -AIPW_vectors)\n",
    "\n",
    "        data[client_id] = vw_data\n",
    "        aux[client_id] = {\"X_train\": X_train, \"X_test\": X_test,\n",
    "                          \"A_train\": A_train, \"A_test\": A_test,\n",
    "                          \"Y_train\": Y_train, \"Y_test\": Y_test,\n",
    "                          \"true_costs_train\": true_costs_train, \"true_costs_test\": true_costs_test,\n",
    "                          \"weight\": weights[client_id]}\n",
    "    \n",
    "    return data, aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9a10076a-3421-491c-af90-98567a6236a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Federated config\n",
    "NUM_ROUNDS = 3\n",
    "NUM_CLIENTS = 4\n",
    "NUM_ACTIONS = 4\n",
    "NUM_FEATURES = 10\n",
    "TRAIN_SIZES = np.array([1, 1, 1, 1]) * 100_000\n",
    "CLIENT_WEIGHTS = TRAIN_SIZES / np.sum(TRAIN_SIZES)\n",
    "\n",
    "# Generate data\n",
    "data, aux = generate_observational_data(num_clients=NUM_CLIENTS,\n",
    "                                        num_actions=NUM_ACTIONS,\n",
    "                                        num_features=NUM_FEATURES,\n",
    "                                        train_sizes=TRAIN_SIZES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480eb501-70c5-4b1e-a230-7c263d05a812",
   "metadata": {},
   "source": [
    "### Train optimal local model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "330a9ebc-85b1-4cce-9cbd-6bbe5bd8e317",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local Client 0: opt_reward=7.894604964354001, reward=7.894345217957393, regret=0.00025974639661475367\n"
     ]
    }
   ],
   "source": [
    "# Set sample size\n",
    "sample_size = 100_000\n",
    "\n",
    "# Train on local data\n",
    "client_id = 0\n",
    "opt_model = VW(csoaa=NUM_ACTIONS,\n",
    "               convert_to_vw=False,\n",
    "               convert_labels=False,\n",
    "               passes=10)\n",
    "opt_model.fit(data[client_id][:sample_size])\n",
    "\n",
    "# Evaluate on test data\n",
    "X_test_vw = utils.to_vw_format(aux[client_id][\"X_test\"])\n",
    "regret, opt_reward, reward = utils.compute_regret(X_test_vw, opt_model, aux[client_id][\"true_costs_test\"])\n",
    "print(f\"Local Client {client_id}: opt_reward={opt_reward}, reward={reward}, regret={regret}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd178226-d706-4896-a925-9cc09b553cc0",
   "metadata": {},
   "source": [
    "### Train local model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f1c53ab4-5ebd-4d1b-8c69-0962ec904c0c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local Client 0: opt_reward=7.894345217957393, reward=7.864565790277059, regret=0.029779427680330383\n",
      "Random Local Client 0: opt_reward=7.894345217957393, reward=0.757282999227291, regret=7.1370622187300965\n"
     ]
    }
   ],
   "source": [
    "# Set sample size\n",
    "sample_size = 1000\n",
    "\n",
    "# Train on local data\n",
    "client_id = 0\n",
    "model = VW(csoaa=NUM_ACTIONS,\n",
    "           convert_to_vw=False,\n",
    "           convert_labels=False,\n",
    "           passes=10)\n",
    "model.fit(data[client_id][:sample_size])\n",
    "\n",
    "# Evaluate on test data\n",
    "X_test_vw = utils.to_vw_format(aux[client_id][\"X_test\"])\n",
    "regret, opt_reward, reward = utils.compute_regret(X_test_vw, model, aux[client_id][\"true_costs_test\"], opt_model)\n",
    "print(f\"Local Client {client_id}: opt_reward={opt_reward}, reward={reward}, regret={regret}\")\n",
    "\n",
    "class Model():\n",
    "    def predict(self, X):\n",
    "        return np.random.choice(NUM_ACTIONS, size=len(X_test_vw))\n",
    "regret, opt_reward, reward = utils.compute_regret(X_test_vw, Model(), aux[client_id][\"true_costs_test\"], opt_model)\n",
    "print(f\"Random Local Client {client_id}: opt_reward={opt_reward}, reward={reward}, regret={regret}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152cde56-e232-47e4-a0be-26eea835fd28",
   "metadata": {},
   "source": [
    "### Train aggregate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5af5bde0-7225-4d63-b77b-f9460c0ead7e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregate: opt_reward=6.393984563552918, reward=6.385915978240404, regret=0.008068585312514958\n"
     ]
    }
   ],
   "source": [
    "# Set sample size\n",
    "sample_sizes = [1000] * NUM_CLIENTS\n",
    "\n",
    "# Aggregate all data\n",
    "X_train = []\n",
    "A_train = []\n",
    "Y_train = []\n",
    "true_costs_train = []\n",
    "true_costs_test = []\n",
    "X_test = []\n",
    "for client_id in range(NUM_CLIENTS):\n",
    "    sample_size = sample_sizes[client_id]\n",
    "    X_train.extend(aux[client_id][\"X_train\"][:sample_size])\n",
    "    A_train.extend(aux[client_id][\"A_train\"][:sample_size])\n",
    "    Y_train.extend(aux[client_id][\"Y_train\"][:sample_size])\n",
    "    true_costs_train.extend(aux[client_id][\"true_costs_train\"][:sample_size])\n",
    "    true_costs_test.extend(aux[client_id][\"true_costs_test\"])\n",
    "    X_test.extend(aux[client_id][\"X_test\"])\n",
    "X_train = np.array(X_train)\n",
    "A_train = np.array(A_train)\n",
    "Y_train = np.array(Y_train)\n",
    "true_costs_train = np.array(true_costs_train)\n",
    "true_costs_test = np.array(true_costs_test)\n",
    "X_test = np.array(X_test)\n",
    "\n",
    "# Compute AIPW scores\n",
    "crossfit_map, mu, e = utils.cross_fit_nuisance_params(X_train, A_train, Y_train, NUM_ACTIONS)\n",
    "noisy_costs_train = -utils.compute_AIPW_scores(X_train, A_train, Y_train, NUM_ACTIONS, crossfit_map, mu, e)\n",
    "data_train = utils.to_vw_format(X_train, A_train, noisy_costs_train)\n",
    "\n",
    "# Train model\n",
    "model = VW(csoaa=NUM_ACTIONS,\n",
    "           convert_to_vw=False,\n",
    "           convert_labels=False,\n",
    "           passes=10)\n",
    "model.fit(data_train)\n",
    "\n",
    "# Evaluate on test data\n",
    "X_test_vw = utils.to_vw_format(X_test)\n",
    "regret, opt_reward, reward = utils.compute_regret(X_test_vw, model, true_costs_test, opt_model)\n",
    "# y_pred = model.predict(X_test_vw)\n",
    "# print(y_pred[-100:])\n",
    "# print(model.get_coefs())\n",
    "print(f\"Aggregate: opt_reward={opt_reward}, reward={reward}, regret={regret}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e707cc92-d187-42eb-a011-c6db96812415",
   "metadata": {},
   "source": [
    "### Train optimal global model (pooled & weighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "74efe0c1-cddb-4d5d-8c68-a92d4a5da267",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregate: opt_reward=3.6447416928682155, reward=3.6446037649485157, regret=0.00013792791969857574\n"
     ]
    }
   ],
   "source": [
    "# Aggregate all data\n",
    "X_train = []\n",
    "A_train = []\n",
    "Y_train = []\n",
    "true_costs_train = []\n",
    "true_costs_test = []\n",
    "X_test = []\n",
    "\n",
    "count = 0\n",
    "idx_to_weight_mapping = {}\n",
    "for client_id in range(NUM_CLIENTS):\n",
    "    lo = len(X_train)\n",
    "    X_train.extend(aux[client_id][\"X_train\"])\n",
    "    A_train.extend(aux[client_id][\"A_train\"])\n",
    "    Y_train.extend(aux[client_id][\"Y_train\"])\n",
    "    true_costs_train.extend(aux[client_id][\"true_costs_train\"])\n",
    "    true_costs_test.extend(aux[client_id][\"true_costs_test\"])\n",
    "    X_test.extend(aux[client_id][\"X_test\"])\n",
    "    hi = len(X_train)\n",
    "    idx_to_weight_mapping.update({i:aux[client_id][\"weight\"]*sum(TRAIN_SIZES)/TRAIN_SIZES[client_id] for i in range(lo, len(X_train))})\n",
    "    \n",
    "X_train = np.array(X_train)\n",
    "A_train = np.array(A_train)\n",
    "Y_train = np.array(Y_train)\n",
    "true_costs_train = np.array(true_costs_train)\n",
    "true_costs_test = np.array(true_costs_test)\n",
    "X_test = np.array(X_test)\n",
    "\n",
    "# Compute AIPW scores\n",
    "crossfit_map, mu, e = utils.cross_fit_nuisance_params(X_train, A_train, Y_train, NUM_ACTIONS)\n",
    "noisy_costs_train = -utils.compute_AIPW_scores(X_train, A_train, Y_train, NUM_ACTIONS, crossfit_map, mu, e)\n",
    "data_train = utils.to_vw_format(X_train, A_train, noisy_costs_train, idx_to_weight_mapping)\n",
    "\n",
    "# Train model\n",
    "opt_model = VW(csoaa=NUM_ACTIONS,\n",
    "               convert_to_vw=False,\n",
    "               convert_labels=False,\n",
    "               passes=10)\n",
    "opt_model.fit(data_train)\n",
    "\n",
    "# Evaluate on test data\n",
    "X_test_vw = utils.to_vw_format(X_test)\n",
    "regret, opt_reward, reward = utils.compute_regret(X_test_vw, opt_model, true_costs_test, opt_model=None, idx_to_weight_mapping=idx_to_weight_mapping)\n",
    "# y_pred = model.predict(X_test_vw)\n",
    "# print(y_pred[-100:])\n",
    "# print(model.get_coefs())\n",
    "print(f\"Aggregate: opt_reward={opt_reward}, reward={reward}, regret={regret}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc5729e-42c9-421d-bec1-d40e1abd0f5f",
   "metadata": {},
   "source": [
    "### Train federated model (weighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8ef9c583-9e9b-4d8d-a0f3-daf7d61ed143",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2023-04-21 04:26:18,940 | app.py:145 | Starting Flower simulation, config: ServerConfig(num_rounds=3, round_timeout=None)\n",
      "2023-04-21 04:26:26,832\tINFO worker.py:1529 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8277 \u001b[39m\u001b[22m\n",
      "INFO flwr 2023-04-21 04:26:28,357 | app.py:179 | Flower VCE: Ray initialized with resources: {'memory': 5147116749.0, 'object_store_memory': 2147483648.0, 'CPU': 8.0, 'node:127.0.0.1': 1.0}\n",
      "INFO flwr 2023-04-21 04:26:28,359 | server.py:86 | Initializing global parameters\n",
      "INFO flwr 2023-04-21 04:26:28,360 | server.py:270 | Requesting initial parameters from one random client\n",
      "INFO flwr 2023-04-21 04:26:29,417 | server.py:274 | Received initial parameters from one random client\n",
      "INFO flwr 2023-04-21 04:26:29,418 | server.py:88 | Evaluating initial parameters\n",
      "INFO flwr 2023-04-21 04:26:29,419 | server.py:101 | FL starting\n",
      "DEBUG flwr 2023-04-21 04:26:29,419 | server.py:215 | fit_round 1: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_get_parameters pid=39499)\u001b[0m [Client 1] get_parameters\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=39499)\u001b[0m Client 0, training finished for round 1\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=39499)\u001b[0m [Client 0] get_parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-04-21 04:26:30,593 | server.py:229 | fit_round 1 received 4 results and 0 failures\n",
      "WARNING flwr 2023-04-21 04:26:30,616 | fedavg.py:242 | No fit_metrics_aggregation_fn provided\n",
      "DEBUG flwr 2023-04-21 04:26:30,618 | server.py:165 | evaluate_round 1: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=39497)\u001b[0m Client 1, training finished for round 1\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=39497)\u001b[0m [Client 1] get_parameters\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=39502)\u001b[0m Client 3, training finished for round 1\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=39502)\u001b[0m [Client 3] get_parameters\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=39498)\u001b[0m Client 2, training finished for round 1\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=39498)\u001b[0m [Client 2] get_parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-04-21 04:26:30,801 | server.py:179 | evaluate_round 1 received 4 results and 0 failures\n",
      "DEBUG flwr 2023-04-21 04:26:30,802 | server.py:215 | fit_round 2: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=39499)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=39497)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=39502)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=39498)\u001b[0m [Client 3] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-04-21 04:26:31,067 | server.py:229 | fit_round 2 received 4 results and 0 failures\n",
      "DEBUG flwr 2023-04-21 04:26:31,097 | server.py:165 | evaluate_round 2: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=39499)\u001b[0m Client 2, training finished for round 2\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=39499)\u001b[0m [Client 2] get_parameters\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=39497)\u001b[0m Client 0, training finished for round 2\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=39497)\u001b[0m [Client 0] get_parameters\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=39502)\u001b[0m Client 1, training finished for round 2\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=39502)\u001b[0m [Client 1] get_parameters\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=39498)\u001b[0m Client 3, training finished for round 2\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=39498)\u001b[0m [Client 3] get_parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-04-21 04:26:31,260 | server.py:179 | evaluate_round 2 received 4 results and 0 failures\n",
      "DEBUG flwr 2023-04-21 04:26:31,262 | server.py:215 | fit_round 3: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=39499)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=39497)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=39502)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=39498)\u001b[0m [Client 3] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=39499)\u001b[0m Client 0, training finished for round 3\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=39499)\u001b[0m [Client 0] get_parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-04-21 04:26:31,535 | server.py:229 | fit_round 3 received 4 results and 0 failures\n",
      "DEBUG flwr 2023-04-21 04:26:31,561 | server.py:165 | evaluate_round 3: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=39497)\u001b[0m Client 1, training finished for round 3\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=39497)\u001b[0m [Client 1] get_parameters\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=39502)\u001b[0m Client 3, training finished for round 3\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=39502)\u001b[0m [Client 3] get_parameters\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=39498)\u001b[0m Client 2, training finished for round 3\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=39498)\u001b[0m [Client 2] get_parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-04-21 04:26:31,727 | server.py:179 | evaluate_round 3 received 4 results and 0 failures\n",
      "INFO flwr 2023-04-21 04:26:31,728 | server.py:144 | FL finished in 2.3085987319991546\n",
      "INFO flwr 2023-04-21 04:26:31,729 | app.py:202 | app_fit: losses_distributed [(1, 0.7726766192184403), (2, 0.7726766192184403), (3, 0.7726766192184403)]\n",
      "INFO flwr 2023-04-21 04:26:31,730 | app.py:203 | app_fit: metrics_distributed {'opt_reward': [(1, 3.2902429044683608), (2, 3.4989963815954925), (3, 3.551511070610543)], 'reward': [(1, 1.82909366445219), (2, 1.8931299359173421), (3, 1.985364991479188)], 'regret': [(1, 1.4611492400161732), (2, 1.605866445678153), (3, 1.5661460791313573)]}\n",
      "INFO flwr 2023-04-21 04:26:31,731 | app.py:204 | app_fit: losses_centralized []\n",
      "INFO flwr 2023-04-21 04:26:31,732 | app.py:205 | app_fit: metrics_centralized {}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=39499)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=39497)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=39502)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=39498)\u001b[0m [Client 3] evaluate, config: {}\n"
     ]
    }
   ],
   "source": [
    "# Set sample size\n",
    "sample_sizes = [1000] * NUM_CLIENTS\n",
    "sample_sizes[0] = 100\n",
    "\n",
    "# Subsample data\n",
    "data_mod = {}\n",
    "aux_mod = {}\n",
    "client_weights = []\n",
    "for client_id in range(NUM_CLIENTS):\n",
    "    sample_size = sample_sizes[client_id]\n",
    "    data_mod[client_id] = data[client_id][:sample_size]\n",
    "    aux_mod[client_id] = {\"X_test\": aux[client_id][\"X_test\"][:sample_size],\n",
    "                          \"true_costs_test\": aux[client_id][\"true_costs_test\"][:sample_size]}\n",
    "    client_weights.append(aux[client_id][\"weight\"])\n",
    "\n",
    "# Run federated learning\n",
    "global_vw = server.run_federated_learning(data_mod, aux_mod, opt_model,\n",
    "                                          num_features=NUM_FEATURES,\n",
    "                                          num_classes=NUM_ACTIONS,\n",
    "                                          num_rounds=NUM_ROUNDS,\n",
    "                                          num_clients=NUM_CLIENTS,\n",
    "                                          client_weights=client_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "73169894-7010-4458-9c48-971ce9631267",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "History (loss, distributed):\n",
       "\tround 1: 0.7726766192184403\n",
       "\tround 2: 0.7726766192184403\n",
       "\tround 3: 0.7726766192184403\n",
       "History (metrics, distributed):\n",
       "{'opt_reward': [(1, 3.2902429044683608), (2, 3.4989963815954925), (3, 3.551511070610543)], 'reward': [(1, 1.82909366445219), (2, 1.8931299359173421), (3, 1.985364991479188)], 'regret': [(1, 1.4611492400161732), (2, 1.605866445678153), (3, 1.5661460791313573)]}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_vw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d847c6-3f5a-4cff-925f-cb436ec0f1a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
